import os
import asyncio
import re
import json
import glob
import pandas as pd
from datetime import datetime
from playwright.async_api import async_playwright
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType

# ì„¤ì •
BRAND_NAME = "8seconds"
LOCAL_OUTPUT_PATH = "crawlers/data/8seconds_json_files"

# ìˆ˜ì§‘ ëŒ€ìƒ
TARGET_MAP = {
    "Men": {
        "Outer": [
            "https://www.ssfshop.com/8seconds/Coats/list?dspCtgryNo=SFMA42A05A02&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/LeatherJacket/list?dspCtgryNo=SFMA42A05A06&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/DenimJacket/list?dspCtgryNo=SFMA42A05A07&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Jackets/list?dspCtgryNo=SFMA42A19A01&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Cardigans/list?dspCtgryNo=SFMA42A03A02&brandShopNo=BDMA07A01&brndShopId=8SBSS"
        ],
        "Top": [
            "https://www.ssfshop.com/8seconds/T-Shirts/list?dspCtgryNo=SFMA42A01&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Pullovers/list?dspCtgryNo=SFMA42A03A01&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Shirts/list?dspCtgryNo=SFMA42A02&brandShopNo=BDMA07A01&brndShopId=8SBSS"
        ],
        "Bottom": [
            "https://www.ssfshop.com/8seconds/Pants-Trousers/list?dspCtgryNo=SFMA42A04&brandShopNo=BDMA07A01&brndShopId=8SBSS"
        ]
    },
    "Women": {
        "Outer": [
            "https://www.ssfshop.com/8seconds/Jackets/list?dspCtgryNo=SFMA41A21A01&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Leather-Jackets/list?dspCtgryNo=SFMA41A21A04&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Coats/list?dspCtgryNo=SFMA41A07A02&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Cardigans/list?dspCtgryNo=SFMA41A03A02&brandShopNo=BDMA07A01&brndShopId=8SBSS"
        ],
        "Top": [
            "https://www.ssfshop.com/8seconds/Pullovers/list?dspCtgryNo=SFMA41A03A01&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/T-shirts/list?dspCtgryNo=SFMA41A01&brandShopNo=BDMA07A01&brndShopId=8SBSS",
            "https://www.ssfshop.com/8seconds/Shirts-Blouses/list?dspCtgryNo=SFMA41A02&brandShopNo=BDMA07A01&brndShopId=8SBSS"
        ],
        "Bottom": [
            "https://www.ssfshop.com/8seconds/Pants-Trousers/list?dspCtgryNo=SFMA41A04&brandShopNo=BDMA07A01&brndShopId=8SBSS"
        ]
    }
}

# ë°©ë¬¸í•œ ìƒí’ˆ IDë¥¼ ê¸°ë¡í•˜ëŠ” ì§‘í•© (ì¤‘ë³µ ìˆ˜ì§‘ ë°©ì§€ìš©)
visited_products = set()

# Spark ìŠ¤í‚¤ë§ˆ
schema = StructType([
    StructField("gender", StringType(), True),
    StructField("category", StringType(), True),
    StructField("product_id", StringType(), True),
    StructField("raw_json", StringType(), True)
])

sem = asyncio.Semaphore(3)

async def extract_product_data_from_dom(page):
    try:
        await page.wait_for_selector('.gods-name', timeout=10000)

        data = await page.evaluate("""() => {
            const result = {};

            // [1] ê¸°ë³¸ ì •ë³´
            result.goodsNo = window._godNo || "";
            if (!result.goodsNo) {
                const urlMatch = location.href.match(/([A-Z0-9]+)\/good/);
                result.goodsNo = urlMatch ? urlMatch[1] : "";
            }
            result.goodsNm = document.querySelector('#goodDtlTitle')?.innerText.trim();
            
            // [2] í’ˆì ˆ ì—¬ë¶€ í™•ì¸
            const soldOutDiv = document.querySelector('#restockSoldOut');
            const isSoldOutDivVisible = soldOutDiv && soldOutDiv.style.display !== 'none';
            const buyBtn = document.querySelector('.submit .btn.order');
            const isBtnDisabled = buyBtn && buyBtn.classList.contains('disabled');
            result.is_sold_out = isSoldOutDivVisible || isBtnDisabled;
            
            // ê°€ê²©
            const priceTxt = document.querySelector('#godPrice')?.innerText || "0";
            result.price = parseInt(priceTxt.replace(/[^0-9]/g, ''));
            
            // ---------------------------------------------------------
            // [3] ìƒ‰ìƒ ì˜µì…˜ ì¶”ì¶œ (ë‹¤ë¥¸ ìƒ‰ìƒ ìƒí’ˆ ID ì°¾ê¸°)
            // ---------------------------------------------------------
            const otherColorIds = [];
            // ìƒ‰ìƒ ì¸ë„¤ì¼ ì˜ì—­ë§Œ ì •í™•íˆ íƒ€ê²ŸíŒ…
            const colorLabels = document.querySelectorAll('.opt-select.color-thumbs label');
            
            colorLabels.forEach(label => {
                const onclickText = label.getAttribute('onclick') || "";
                
                // [ìˆ˜ì •] ë³µì¡í•œ URL ì „ì²´ ë§¤ì¹­ ëŒ€ì‹ , ìƒí’ˆì½”ë“œ íŒ¨í„´(GM...)ë§Œ ê°•ë ¥í•˜ê²Œ ì¶”ì¶œ
                // ì˜ˆ: .../8-seconds/GM0025103079299/good... -> GM0025103079299 ì¶”ì¶œ
                // SSFìƒµ ìƒí’ˆì½”ë“œëŠ” ë³´í†µ GM, GP, GQ ë“±ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê¸´ ë¬¸ìì—´ì…ë‹ˆë‹¤.
                const idMatch = onclickText.match(/\/([A-Z0-9]{10,})\/good/);
                
                if (idMatch) {
                    const extractedId = idMatch[1];
                    // í˜„ì¬ ìƒí’ˆ IDê°€ ì•„ë‹ˆë©´ ìˆ˜ì§‘ ëª©ë¡ì— ì¶”ê°€
                    if (extractedId !== result.goodsNo) {
                        otherColorIds.push(extractedId);
                    }
                }
            });
            // ì¤‘ë³µ ì œê±°
            result.other_color_ids = [...new Set(otherColorIds)];


            // ---------------------------------------------------------
            // [4] ì‚¬ì´ì¦ˆë³„ ì¬ê³  ìƒì„¸ íŒŒì‹± (ë°°ì†¡ë°©ë²• ì œì™¸)
            // ---------------------------------------------------------
            const sizeStockInfo = [];
            
            //'ì‚¬ì´ì¦ˆ'ë¼ëŠ” ì œëª©ì„ ê°€ì§„ .row ì˜ì—­ë§Œ íŠ¹ì •í•´ì„œ ì°¾ìŒ
            const rows = Array.from(document.querySelectorAll('.gods-option .row'));
            let sizeRow = null;
            
            for (const row of rows) {
                const title = row.querySelector('.tit')?.innerText.trim();
                if (title === 'ì‚¬ì´ì¦ˆ') {
                    sizeRow = row;
                    break; 
                }
            }

            if (sizeRow) {
                // 'ì‚¬ì´ì¦ˆ' ì˜ì—­ ì•ˆì˜ lië§Œ ê°€ì ¸ì˜´
                const sizeItems = sizeRow.querySelectorAll('.rdo_group li');
                
                sizeItems.forEach(li => {
                    const sizeName = li.querySelector('label')?.innerText.trim();
                    const inputId = li.querySelector('input')?.id; 
                    
                    if (sizeName && inputId) {
                        // hidden input ID ìœ ì¶” (ra_ -> sizeItmNo)
                        // ì˜ˆ: ra_IT202510206874710 -> sizeItmNoIT202510206874710
                        const hiddenInputId = inputId.replace('ra_', 'sizeItmNo');
                        const hiddenInput = document.getElementById(hiddenInputId);
                        
                        let stockQty = 0;
                        let isSoldOut = false;

                        if (hiddenInput) {
                            // hidden íƒœê·¸ì˜ ì†ì„±ê°’ì—ì„œ ì •ë³´ ì¶”ì¶œ
                            stockQty = parseInt(hiddenInput.getAttribute('onlineusefulinvqty') || "0");
                            const statCd = hiddenInput.getAttribute('itmstatcd'); 
                            
                            // ì¬ê³  0ì´ê±°ë‚˜ í’ˆì ˆìƒíƒœì½”ë“œë©´ True
                            if (stockQty <= 0 || statCd === 'SLDOUT') isSoldOut = true;
                        }

                        // li íƒœê·¸ ìì²´ì— disabled í´ë˜ìŠ¤ê°€ ìˆê±°ë‚˜ ìˆ¨ê²¨ì ¸ ìˆìœ¼ë©´ í’ˆì ˆ
                        if (li.classList.contains('disabled') || li.style.display === 'none') {
                            isSoldOut = true;
                        }

                        sizeStockInfo.push({
                            size: sizeName,
                            stock_qty: stockQty,
                            is_sold_out: isSoldOut
                        });
                    }
                });
            }
            result.size_stock = sizeStockInfo;


            // [5] ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            const thumbImgs = Array.from(document.querySelectorAll('.preview-thumb .thumb-item'));
            const detailImgs = Array.from(document.querySelectorAll('.gods-detail-img img'));
            const contentImgs = Array.from(document.querySelectorAll('.gods-tab-view img'));
            
            const allImages = [...thumbImgs.map(el => el.getAttribute('data')), 
                               ...detailImgs.map(img => img.getAttribute('data-original') || img.src),
                               ...contentImgs.map(img => img.getAttribute('data-original') || img.src)];
            
            result.goodsImages = [...new Set(allImages)]
                .filter(url => url && !url.includes('noImg'))
                .map(url => {
                    if (url.startsWith('//')) return 'https:' + url;
                    if (url.startsWith('/')) return 'https://img.ssfshop.com' + url;
                    return url;
                });

            // [6] ìƒì„¸ ìŠ¤í™ í…Œì´ë¸”
            const specInfo = {};
            document.querySelectorAll('.tbl-info tbody tr').forEach(row => {
                const key = row.querySelector('th')?.innerText.trim();
                const val = row.querySelector('td')?.innerText.trim().replace(/\\n/g, ' ');
                if(key && val) specInfo[key] = val;
            });
            result.goodsMaterial = specInfo;

            // [7] ì‹¤ì¸¡ ì‚¬ì´ì¦ˆí‘œ
            const sizeChart = [];
            const sizeTable = document.querySelector('.brand-size table');
            if (sizeTable) {
                const headers = Array.from(sizeTable.querySelectorAll('thead th')).map(th => th.innerText.trim());
                const rows = sizeTable.querySelectorAll('tbody tr');
                rows.forEach(row => {
                    const rowData = {};
                    const cells = Array.from(row.querySelectorAll('td'));
                    if(cells.length > 0) rowData['SIZE'] = cells[0].innerText.trim();
                    for(let i=1; i<cells.length; i++) {
                        const key = headers[i] || `col_${i}`; 
                        rowData[key] = cells[i].innerText.trim();
                    }
                    sizeChart.push(rowData);
                });
            }
            result.sizeChart = sizeChart;

            return result;
        }""")
        
        data['url'] = page.url
        data['scraped_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        return data

    except Exception as e:
        print(f"   âŒ DOM íŒŒì‹± ì‹¤íŒ¨: {str(e)[:100]}")
        return None

async def process_product(product_id, gender, category, context, collected_data):
    # 1. ì´ë¯¸ ìˆ˜ì§‘í•œ ìƒí’ˆ(ID)ì´ë©´ ì¦‰ì‹œ ì¢…ë£Œ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    if product_id in visited_products:
        return
    
    # ë°©ë¬¸ ë„ì¥ ì°ê¸°
    visited_products.add(product_id)

    async with sem:
        url = f"https://www.ssfshop.com/8-seconds/{product_id}/good?brandShopNo=BDMA07A01&brndShopId=8SBSS"
        p_page = await context.new_page()
        try:
            print(f"   ğŸ” {product_id} ì ‘ì† ì¤‘...")
            await p_page.goto(url, timeout=60000, wait_until="load")
            await asyncio.sleep(2) 
            
            product_dict = await extract_product_data_from_dom(p_page)
            
            if product_dict:
                # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                collected_data.append({
                    "gender": gender,
                    "category": category,
                    "product_id": product_id,
                    "raw_json": json.dumps(product_dict, ensure_ascii=False)
                })
                
                # ë¡œê·¸ ì¶œë ¥ (í’ˆì ˆ ì—¬ë¶€ í¬í•¨)
                status = "ğŸš«í’ˆì ˆ" if product_dict.get('is_sold_out') else "ğŸŸ¢íŒë§¤ì¤‘"
                print(f"   âœ… {product_id} ìˆ˜ì§‘ ì™„ë£Œ [{status}]")

                # [ì¬ê·€ í˜¸ì¶œ] ë‹¤ë¥¸ ìƒ‰ìƒ ìƒí’ˆë“¤ì´ ë°œê²¬ë˜ë©´ ìˆ˜ì§‘ ëª©ë¡ì— ì¶”ê°€
                other_ids = product_dict.get('other_color_ids', [])
                if other_ids:
                    print(f"      â†ªï¸ ë‹¤ë¥¸ ìƒ‰ìƒ {len(other_ids)}ê°œ ë°œê²¬! ì¶”ê°€ ìˆ˜ì§‘ ì‹œì‘...")
                    # í˜„ì¬ í˜ì´ì§€ ë‹«ê³  ë‹¤ë¥¸ ìƒ‰ìƒ ìˆ˜ì§‘í•˜ëŸ¬ ê°
                    await p_page.close()
                    
                    # ë°œê²¬ëœ ë‹¤ë¥¸ ìƒ‰ìƒ IDë“¤ì— ëŒ€í•´ ì¬ê·€ì ìœ¼ë¡œ process_product í˜¸ì¶œ
                    tasks = [process_product(oid, gender, category, context, collected_data) for oid in other_ids]
                    await asyncio.gather(*tasks)
                    return # ì¬ê·€ í˜¸ì¶œ ëë‚˜ë©´ í•¨ìˆ˜ ì¢…ë£Œ

            else:
                print(f"   âš ï¸ {product_id} ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"   âŒ {product_id} ì—ëŸ¬: {str(e)[:50]}")
        finally:
            if not p_page.is_closed():
                await p_page.close()

async def crawl_category(gender, category_name, target_url, context, collected_data):
    print(f"\n>>> ğŸ¯ [{gender}-{category_name}] ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
    page = await context.new_page()
    product_codes = set()
    try:
        await page.goto(target_url, timeout=60000)
        for _ in range(5):
            await page.evaluate("window.scrollBy(0, 3000)")
            await asyncio.sleep(1)
        
        codes = await page.evaluate("""() => 
            Array.from(document.querySelectorAll('li.god-item'))
            .map(item => item.getAttribute('view-godno'))
            .filter(c => c !== null)
        """)
        
        for c in codes: product_codes.add(c)
        print(f"   ğŸ”— ì´ˆê¸° ë°œê²¬ ìƒí’ˆ ìˆ˜: {len(product_codes)}ê°œ")
        await page.close()
        
        # ì „ì²´ ìƒí’ˆ ìˆ˜ì§‘ ì‹œì‘
        tasks = [process_product(code, gender, category_name, context, collected_data) for code in list(product_codes)]
        await asyncio.gather(*tasks)

    except Exception as e:
        print(f"   âŒ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        await page.close()

async def run():
    print(f"--- [START] {BRAND_NAME} ìŠ¤ë§ˆíŠ¸ ìˆ˜ì§‘ (ìƒ‰ìƒì¶”ì /í’ˆì ˆí™•ì¸) ---")
    collected_data = [] 
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True) 
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            viewport={'width': 1920, 'height': 1080}
        )
        
        for gender, categories in TARGET_MAP.items():
            for category, urls in categories.items():
                for url in urls:
                    await crawl_category(gender, category, url, context, collected_data)
        
        await browser.close()

    # Spark ì €ì¥
    if collected_data:
        print(f"\nğŸ“¦ ì´ {len(collected_data)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ (ìƒ‰ìƒ í¬í•¨). Spark ê°€ê³µ ì‹œì‘...")
        pdf = pd.DataFrame(collected_data)
        
        spark = SparkSession.builder \
            .appName(f"{BRAND_NAME}_Crawler") \
            .config("spark.master", "local[1]") \
            .config("spark.driver.memory", "4g") \
            .config("spark.sql.execution.arrow.pyspark.enabled", "true") \
            .getOrCreate()
        
        try:
            df = spark.createDataFrame(pdf, schema=schema).coalesce(1)
            temp_path = f"crawlers/data/temp_{BRAND_NAME}_output"
            df.write.mode("overwrite").json(temp_path)
            
            if not os.path.exists(LOCAL_OUTPUT_PATH):
                os.makedirs(LOCAL_OUTPUT_PATH)

            json_files = glob.glob(f"{temp_path}/*.json")
            count = 0
            for file in json_files:
                with open(file, 'r', encoding='utf-8') as f:
                    for line in f:
                        row = json.loads(line)
                        raw_data = json.loads(row['raw_json'])
                        
                        filename = f"{BRAND_NAME}_{row['gender'].lower()}_{row['category'].lower()}_{row['product_id']}.json"
                        with open(os.path.join(LOCAL_OUTPUT_PATH, filename), 'w', encoding='utf-8') as out_f:
                            json.dump(raw_data, out_f, ensure_ascii=False, indent=4)
                        count += 1
            
            print(f"\nâœ¨ {count}ê°œì˜ íŒŒì¼ì´ '{LOCAL_OUTPUT_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        finally:
            spark.stop()
    else:
        print("\nâŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(run())