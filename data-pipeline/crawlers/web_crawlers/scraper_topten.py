import os
import asyncio
import re
import json
import glob
import pandas as pd
import random
from datetime import datetime
from playwright.async_api import async_playwright
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType

# --- ì„¤ì • ---
BRAND_NAME = "topten"
LOCAL_OUTPUT_PATH = f"crawlers/data/{BRAND_NAME}_json_files"

# ìˆ˜ì§‘ ëŒ€ìƒ URL
TARGET_MAP = {
    "Men": {
        "Outer": [
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA42A06",
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA42A03"
        ],
        "Top": [
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA42A02",
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA42A01",
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA42A04"
        ],
        "Bottom": [
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA42A07",
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA42A21"
        ]
    },
    "Women": {
        "Outer": [
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA41A04A01",
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA41A02"
        ],
        "Top": [
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA41A01",
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA41A03"
        ],
        "Bottom": [
            "https://topten10.goodwearmall.com/display/category/list?dspCtgryNo=SSMA41A06"
        ]
    }
}


visited_products = set()
sem = asyncio.Semaphore(3)

# Spark ìŠ¤í‚¤ë§ˆ
schema = StructType([
    StructField("gender", StringType(), True),
    StructField("category", StringType(), True),
    StructField("product_id", StringType(), True),
    StructField("raw_json", StringType(), True)
])

async def extract_product_data_from_dom(page):
    try:
        for _ in range(3):
            await page.mouse.wheel(0, 500)
            await asyncio.sleep(0.5)
        
        data = await page.evaluate("""() => {
            const result = {};
            
            // ---------------------------------------------------------
            // [1] ê¸°ë³¸ ì •ë³´
            // ---------------------------------------------------------
            result.goodsNo = location.href.match(/\/product\/([A-Z0-9]+)\/detail/)?.[1] || "";
            result.goodsNm = document.querySelector('meta[property="og:title"]')?.content || document.title;
            result.brandName = "TOPTEN10";
            result.thumbnailImageUrl = document.querySelector('meta[property="og:image"]')?.content || "";

            // ---------------------------------------------------------
            // [2] ê°€ê²© (ì •ë°€ íƒ€ê²ŸíŒ…)
            // ---------------------------------------------------------
            let price = 0;
            const metaPrice = document.querySelector('meta[property="product:price:amount"]')?.content;
            if (metaPrice) price = parseInt(metaPrice);
            
            if (price === 0) {
                // ì‚¬ìš©ì ì œë³´ êµ¬ì¡°: div.d-flex.align-items-end > strong
                const containers = document.querySelectorAll('div.d-flex.align-items-end');
                for (const container of containers) {
                    const strongs = container.querySelectorAll('strong');
                    for (const s of strongs) {
                        const txt = s.innerText.replace(/[^0-9]/g, '');
                        // %ê°€ ì—†ê³  ìˆ«ìê°€ ìˆëŠ” ê²½ìš°
                        if (!s.innerText.includes('%') && txt.length > 0) {
                            price = parseInt(txt);
                            break;
                        }
                    }
                    if (price > 0) break;
                }
            }
            result.price = price;

            // ---------------------------------------------------------
            // [3] í’ˆì ˆ ì—¬ë¶€
            // ---------------------------------------------------------
            let isSoldOut = false;
            if (price === 0) isSoldOut = true; // ê°€ê²© ëª» ì°¾ìœ¼ë©´ í’ˆì ˆë¡œ ê°„ì£¼
            
            const buyBtns = document.querySelectorAll('.btn-buy, .btn-order, button');
            for(let btn of buyBtns) {
                const txt = btn.innerText;
                if ((txt.includes('êµ¬ë§¤') || txt.includes('ì¥ë°”êµ¬ë‹ˆ')) && (btn.disabled || txt.includes('í’ˆì ˆ'))) {
                    isSoldOut = true;
                }
            }
            result.is_sold_out = isSoldOut;

            // ---------------------------------------------------------
            // [4] ì‚¬ì´ì¦ˆ ì¬ê³ 
            // ---------------------------------------------------------
            const sizeStockInfo = [];
            document.querySelectorAll('.option-list.size button, .size-area button').forEach(btn => {
                const name = btn.innerText.trim();
                // "ì „ì²´ì‚­ì œ" ê°™ì€ UI ë²„íŠ¼ ì œì™¸, 10ê¸€ì ì´í•˜ë§Œ ì‚¬ì´ì¦ˆë¡œ ì¸ì •
                if (name && name.length < 10 && !name.includes('ì‚­ì œ')) {
                    const isItemSoldOut = btn.classList.contains('soldout') || btn.disabled;
                    sizeStockInfo.push({
                        size: name.replace(/\(.*\)/, '').trim(),
                        is_sold_out: isItemSoldOut,
                        stock_qty: isItemSoldOut ? 0 : 999
                    });
                }
            });
            result.size_stock = sizeStockInfo;

            // ---------------------------------------------------------
            // [5] ìƒ‰ìƒ ì˜µì…˜ (ì‚¬ìš©ì ì œë³´ êµ¬ì¡° ë°˜ì˜: tooltip-box) - í•µì‹¬!
            // ---------------------------------------------------------
            const otherColorIds = [];
            
            // "ì»¬ëŸ¬" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì˜ì—­ì„ ë¨¼ì € ì°¾ê³ , ê·¸ ì£¼ë³€ì˜ ë²„íŠ¼ë“¤ì„ íƒìƒ‰
            // ì œê³µí•´ì£¼ì‹  HTML êµ¬ì¡°: .tooltip-box col-auto > button[onclick*='goGodDetail']
            
            const colorButtons = document.querySelectorAll('.tooltip-box button, .color-chip button, .option-list.color button');
            
            colorButtons.forEach(btn => {
                const onclick = btn.getAttribute('onclick') || "";
                
                // goGodDetail('MSF4KG1501BK', ...) íŒ¨í„´ ì¶”ì¶œ
                const match = onclick.match(/goGodDetail\\(['"]([A-Z0-9]+)['"]/);
                
                if (match && match[1]) {
                    const id = match[1];
                    // í˜„ì¬ ìƒí’ˆ IDì™€ ë‹¤ë¥´ë©´ ì¶”ê°€
                    if (id !== result.goodsNo) {
                        otherColorIds.push(id);
                    }
                }
            });
            
            // ì¤‘ë³µ ì œê±°
            result.other_color_ids = [...new Set(otherColorIds)];

            // ---------------------------------------------------------
            // [6] ì´ë¯¸ì§€
            // ---------------------------------------------------------
            const images = [];
            if (result.thumbnailImageUrl) images.push(result.thumbnailImageUrl);
            
            document.querySelectorAll('img').forEach(img => {
                if (img.src && img.src.includes('goodwearmall') && 
                    !img.src.includes('icon') && !img.src.includes('logo') && 
                    !img.src.includes('banner')) {
                    images.push(img.src);
                }
            });
            result.goodsImages = [...new Set(images)];

            // ---------------------------------------------------------
            // [7] ìŠ¤í™
            // ---------------------------------------------------------
            const specInfo = {};
            document.querySelectorAll('table tbody tr').forEach(row => {
                const key = row.querySelector('th')?.innerText.trim();
                const val = row.querySelector('td')?.innerText.trim().replace(/\\n/g, ' ');
                if (key && val) specInfo[key] = val;
            });
            result.goodsMaterial = specInfo;

            return result;
        }""")
        
        if not data.get('goodsNm'): return None
        data['url'] = page.url
        data['scraped_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        return data

    except Exception:
        return None

async def process_product(product_id, gender, category, context, collected_data):
    if product_id in visited_products: return
    visited_products.add(product_id)
    new_ids = []

    async with sem:
        url = f"https://topten10.goodwearmall.com/product/{product_id}/detail"
        p_page = await context.new_page()
        try:
            print(f"   ğŸ” {product_id} ì ‘ì† ì¤‘...")
            await p_page.goto(url, timeout=60000, wait_until="domcontentloaded")
            
            # ì¬ì‹œë„ ë¡œì§
            product_dict = None
            for _ in range(2):
                product_dict = await extract_product_data_from_dom(p_page)
                if product_dict and product_dict.get('price', 0) > 0: break
                await asyncio.sleep(2)

            if product_dict:
                collected_data.append({
                    "gender": gender, "category": category, "product_id": product_id,
                    "raw_json": json.dumps(product_dict, ensure_ascii=False)
                })
                print(f"   âœ… {product_id} ì™„ë£Œ (ê°€ê²©: {product_dict.get('price')}ì›)")
                
                for oid in product_dict.get('other_color_ids', []):
                    if oid not in visited_products: new_ids.append(oid)
            else:
                print(f"   âš ï¸ {product_id} ë°ì´í„° ì—†ìŒ")

        except Exception as e:
            print(f"   âŒ {product_id} ì—ëŸ¬: {str(e)[:50]}")
        finally:
            await p_page.close()

    if new_ids:
        tasks = [process_product(oid, gender, category, context, collected_data) for oid in new_ids]
        await asyncio.gather(*tasks)

async def crawl_category(gender, category_name, target_url, context, collected_data):
    print(f"\n>>> ğŸ¯ [{gender}-{category_name}] ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
    page = await context.new_page()
    product_ids = set()
    
    try:
        await page.goto(target_url, timeout=60000, wait_until="domcontentloaded")
        
        print("   â³ ë°ì´í„° ë¡œë”© ì¤‘ (HTML ì „ì²´ ìŠ¤ìº” ì¤€ë¹„)...")
        # ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ì„œ lazy loadingëœ ìƒí’ˆë“¤ë„ HTMLì— ë¡œë“œë˜ê²Œ í•¨
        for _ in range(3):
            await page.evaluate("window.scrollBy(0, document.body.scrollHeight)")
            await asyncio.sleep(1.5)
        
        content = await page.content()
        
        # íŒ¨í„´: ì˜ë¬¸3ì + ìˆ«ì1ì + ì˜ë¬¸2ì + ìˆ«ì4ì + ì˜ë¬¸/ìˆ«ì (ì˜ˆ: MSG2KG1001CH)
        matches = re.findall(r"[A-Z]{3}\d[A-Z]{2}\d{4}[A-Z0-9]+", content)
        
        for pid in matches:
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ë…¸ì´ì¦ˆ ë°ì´í„° ì œì™¸ (ìƒí’ˆì½”ë“œëŠ” ë³´í†µ 10~15ì)
            if 10 <= len(pid) <= 15:
                product_ids.add(pid)
        
        print(f"   ğŸ”— ì¶”ì¶œëœ í›„ë³´ ID: {len(product_ids)}ê°œ") # ì´ ë©”ì‹œì§€ê°€ ë‚˜ì™€ì•¼ ìµœì‹  ì½”ë“œì„
        await page.close()
        
        if len(product_ids) == 0:
            print("   âŒ ID ì¶”ì¶œ ì‹¤íŒ¨. HTML ì†ŒìŠ¤ì— íŒ¨í„´ì´ ì—†ê±°ë‚˜ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        tasks = [process_product(pid, gender, category_name, context, collected_data) for pid in list(product_ids)]
        await asyncio.gather(*tasks)

    except Exception as e:
        print(f"   âŒ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        await page.close()

async def run():
    print(f"--- [START] TOPTEN ìµœì¢… ì •ê·œì‹ ë²„ì „ ---")
    collected_data = [] 
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=["--start-maximized", "--disable-blink-features=AutomationControlled"]
        ) 
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            locale="ko-KR",
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
        )
        
        await context.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

        for gender, categories in TARGET_MAP.items():
            for category, urls in categories.items():
                if isinstance(urls, str): urls = [urls]
                for url in urls:
                    await crawl_category(gender, category, url, context, collected_data)
        
        await browser.close()

    if collected_data:
        print(f"\nğŸ“¦ {len(collected_data)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ. Spark ì €ì¥ ì‹œì‘...")
        pdf = pd.DataFrame(collected_data)
        
        spark = SparkSession.builder \
            .appName(f"{BRAND_NAME}_Crawler") \
            .config("spark.master", "local[1]") \
            .config("spark.driver.memory", "4g") \
            .config("spark.sql.execution.arrow.pyspark.enabled", "true") \
            .getOrCreate()
        
        try:
            df = spark.createDataFrame(pdf, schema=schema).coalesce(1)
            temp_path = f"crawlers/data/temp_{BRAND_NAME}_output"
            df.write.mode("overwrite").json(temp_path)
            
            if not os.path.exists(LOCAL_OUTPUT_PATH):
                os.makedirs(LOCAL_OUTPUT_PATH)

            json_files = glob.glob(f"{temp_path}/*.json")
            for file in json_files:
                with open(file, 'r', encoding='utf-8') as f:
                    for line in f:
                        row = json.loads(line)
                        raw_data = json.loads(row['raw_json'])
                        filename = f"{BRAND_NAME}_{row['gender'].lower()}_{row['category'].lower()}_{row['product_id']}.json"
                        with open(os.path.join(LOCAL_OUTPUT_PATH, filename), 'w', encoding='utf-8') as out_f:
                            json.dump(raw_data, out_f, ensure_ascii=False, indent=4)
            print(f"\nâœ¨ ì €ì¥ ì™„ë£Œ: {LOCAL_OUTPUT_PATH}")
        finally:
            spark.stop()
    else:
        print("\nâŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(run())